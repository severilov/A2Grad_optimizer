{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fiSHwkvZumRd"
   },
   "outputs": [],
   "source": [
    "from util import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p2Mo1UdyumT9",
    "outputId": "f14053f0-1237-42a4-f9ee-f5c16460b496"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./MNIST\"\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACC ADD GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer, required\n",
    "import copy\n",
    "\n",
    "class AccSGD(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=required, kappa = 1000.0, xi = 10.0, smallConst = 0.7, weight_decay=0):\n",
    "        defaults = dict(lr=lr, kappa=kappa, xi=xi, smallConst=smallConst,\n",
    "                        weight_decay=weight_decay)\n",
    "        super(AccSGD, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(AccSGD, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group['weight_decay']\n",
    "            large_lr = (group['lr']*group['kappa'])/(group['smallConst'])\n",
    "            Alpha = 1.0 - ((group['smallConst']*group['smallConst']*group['xi'])/group['kappa'])\n",
    "            Beta = 1.0 - Alpha\n",
    "            zeta = group['smallConst']/(group['smallConst']+Beta)\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "                if weight_decay != 0:\n",
    "                    d_p.add_(weight_decay, p.data)\n",
    "                param_state = self.state[p]\n",
    "                if 'momentum_buffer' not in param_state:\n",
    "                    param_state['momentum_buffer'] = copy.deepcopy(p.data)\n",
    "                buf = param_state['momentum_buffer']\n",
    "                buf.mul_((1.0/Beta)-1.0)\n",
    "                buf.add_(-large_lr,d_p)\n",
    "                buf.add_(p.data)\n",
    "                buf.mul_(Beta)\n",
    "\n",
    "                p.data.add_(-group['lr'],d_p)\n",
    "                p.data.mul_(zeta)\n",
    "                p.data.add_(1.0-zeta,buf)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer, required\n",
    "import copy\n",
    "import math\n",
    "\n",
    "class A2Grad(Optimizer):\n",
    "\n",
    "    def __init__(self, params, beta=50, lips=10):\n",
    "        defaults = dict(beta=beta, lips=lips)\n",
    "        super(A2Grad, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(A2Grad, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"\"\" Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "                state = self.state[p]\n",
    "\n",
    "                \n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['alpha'] = 1\n",
    "                    state['h_k'] = copy.deepcopy(p.data)\n",
    "                    state['x_k'] = copy.deepcopy(p.data)\n",
    "                \n",
    "                state['step'] += 1\n",
    "                \n",
    "                alpha_k = 2/(state['step']+2)\n",
    "                gamma_k = 2*group['lips']/(state['step']+1)\n",
    "                \n",
    "                h_k = state['h_k']\n",
    "                h_k.mul_(state['step'])\n",
    "                h_k.add_(p.data)\n",
    "                h_k.div_(state['step']+1)\n",
    "                #h_k = (state['step']/(state['step']))*state['h_k']+p.data\n",
    "                \n",
    "                \n",
    "                coef = 1/(gamma_k+group['beta']*h_k)\n",
    "                x_k = state['x_k']\n",
    "                x_k.add_(torch.mul(-coef, d_p))\n",
    "                \n",
    "                p.data.mul_(1-alpha_k)\n",
    "                p.data.add_(torch.mul(alpha_k, x_k))\n",
    "                p.data.add_(torch.mul((1-alpha_k)*alpha_k/(gamma_k+group['beta']*h_k), d_p))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6Lk5gvGu1Yc"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rk3Q_Jku2by"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "valid_dataset = torchvision.datasets.MNIST(root='../data', train=True, \n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYLS8LcHWv7n"
   },
   "outputs": [],
   "source": [
    "valid_size=0.15\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "               batch_size=batch_size, sampler=train_sampler,\n",
    "               num_workers=2)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(valid_dataset, \n",
    "               batch_size=batch_size, sampler=valid_sampler,\n",
    "               num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "7j9cjtv5u57l",
    "outputId": "2d6a7e4b-aa09-49fd-9dbd-d0e3f65ff814"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  tensor([2, 0, 0, 2])\n",
      "Batch shape:  torch.Size([4, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_batch(batch):\n",
    "    im = torchvision.utils.make_grid(batch)\n",
    "    plt.imshow(np.transpose(im.numpy(), (1, 2, 0)))\n",
    "    \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print('Labels: ', labels)\n",
    "print('Batch shape: ', images.size())\n",
    "show_batch(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THk9uDZku-gM"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pnS_0OICbHF4"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6micuYGbGOL"
   },
   "outputs": [],
   "source": [
    "class LR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LR, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = F.log_softmax(self.linear1(x.view(batch_size, -1)), -1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4rjRazJa-S6"
   },
   "source": [
    "###   Two-layer neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uh3HnmUmu96Q"
   },
   "outputs": [],
   "source": [
    "class FC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FC, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 256)\n",
    "        self.linear2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_relu = F.relu(self.linear1(x.view(batch_size, -1)))\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SSTdIH_vKV5"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nMttjLlZrbcd"
   },
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def model_step(model, optimizer, criterion, inputs, labels):\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    if model.training:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "    if optimizer.__class__.__name__ != 'SUG':\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            upd_outputs = model(inputs)\n",
    "            upd_loss = criterion(upd_outputs, labels)\n",
    "            upd_loss.backward()\n",
    "            return upd_loss\n",
    "\n",
    "        optimizer.step(loss, closure)\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMgATVQnvIiy"
   },
   "outputs": [],
   "source": [
    "def train(model, trainloader, criterion, optimizer, n_epochs=2, validloader=None, eps=1e-5, print_every=1):\n",
    "    tr_loss, val_loss, lips, times, grad, acc = ([] for i in range(6))\n",
    "    start_time = time.time()\n",
    "    model.to(device=device)\n",
    "    for ep in range(n_epochs):\n",
    "        model.train()\n",
    "        i = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).to(device=device), Variable(labels).to(device=device)\n",
    "\n",
    "            tr_loss.append(model_step(model, optimizer, criterion, inputs, labels))\n",
    "            if optimizer.__class__.__name__ == 'SUG':\n",
    "                lips.append(optimizer.get_lipsitz_const())\n",
    "                grad.append(optimizer.get_sq_grad)\n",
    "        times.append(time_since(start_time))\n",
    "        if ep % print_every == 0:\n",
    "            print(\"Epoch {}, training loss {}, time passed {}\".format(ep, sum(tr_loss[-i:]) / i, time_since(start_time)))\n",
    "\n",
    "        if validloader is None:\n",
    "            continue\n",
    "        model.zero_grad()\n",
    "        model.eval()\n",
    "        j = 0\n",
    "        for j, data in enumerate(validloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device=device), labels.to(device=device)\n",
    "            val_loss.append(model_step(model, optimizer, criterion, inputs, labels))\n",
    "        if ep % print_every == 0:\n",
    "            print(\"Validation loss {}\".format(sum(val_loss[-j:]) / j))\n",
    "        \n",
    "    return tr_loss, times, val_loss, lips, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sz4svVB3vNyZ"
   },
   "outputs": [],
   "source": [
    "print_every = 2\n",
    "n_epochs = 6\n",
    "tr_loss = {}\n",
    "tr_loss['accSGD'] = {}\n",
    "tr_loss['Adam'] = {}\n",
    "tr_loss['amsgrad'] = {}\n",
    "tr_loss['sug'] = {}\n",
    "tr_loss['A2Grad'] = {}\n",
    "val_loss = {}\n",
    "val_loss['accSGD'] = {}\n",
    "val_loss['Adam'] = {}\n",
    "val_loss['amsgrad'] = {}\n",
    "val_loss['sug'] = {}\n",
    "val_loss['A2Grad'] = {}\n",
    "lrs = [0.001]#[0.1, 0.01, 0.001]\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6jCFM66X7ql"
   },
   "outputs": [],
   "source": [
    "def concat_states(state1, state2):\n",
    "    states = {\n",
    "            'epoch': state1['epoch'] + state2['epoch'],\n",
    "            'state_dict': state2['state_dict'],\n",
    "            'optimizer': state2['optimizer'],\n",
    "            'tr_loss' : state1['tr_loss'] + state2['tr_loss'],\n",
    "            'val_loss' : state1['val_loss'] + state2['val_loss'],\n",
    "            'lips' : state1['lips'] + state2['lips'],\n",
    "            'grad' : state1['grad'] + state2['grad'],\n",
    "            #'times' : state1['times'] + list(map(lambda x: x + state1['times'][-1],state2['times']))\n",
    "             'times' : state1['times'] + state2['times']\n",
    "             }\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "98EHtawSzoTM"
   },
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "hTMWs2dYznyO",
    "outputId": "01e33386-4143-4fe1-ead2-ef3ccd13cea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam  lr=0.001:\n",
      "Epoch 0, training loss 0.4471673777217208, time passed 0m 17s\n",
      "Validation loss 0.48481341447177106\n",
      "Epoch 2, training loss 0.39360389989321554, time passed 0m 54s\n",
      "Validation loss 0.4692441363024516\n",
      "Epoch 4, training loss 0.38341145817109673, time passed 1m 35s\n",
      "Validation loss 0.5846125006058818\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = LR()\n",
    "    print(\"Adam  lr={}:\".format(lr))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    tr_loss['Adam'][lr], times, val_loss['Adam'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['Adam'][lr],\n",
    "            'val_loss' : val_loss['Adam'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './MNIST/LR_Adam_' + str(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2Grad  lr=0.001:\n",
      "Epoch 0, training loss 7953.257572018237, time passed 0m 19s\n",
      "Validation loss 13981.138626417514\n",
      "Epoch 2, training loss 15366.253319625022, time passed 1m 2s\n",
      "Validation loss 15248.523625409036\n",
      "Epoch 4, training loss 16415.311523877946, time passed 1m 52s\n",
      "Validation loss 16777.58534695976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _get_module_lock.<locals>.cb at 0x11f2b80d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen importlib._bootstrap>\", line 182, in cb\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-4ab9393a2c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                          \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                          \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                                                          validloader=validloader)\n\u001b[0m\u001b[1;32m      9\u001b[0m     states = {\n\u001b[1;32m     10\u001b[0m             \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-855b0e20dc27>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, criterion, optimizer, n_epochs, validloader, eps, print_every)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = LR()\n",
    "    print(\"A2Grad  lr={}:\".format(lr))\n",
    "    optimizer = A2Grad(model.parameters())\n",
    "    tr_loss['A2Grad'][lr], times, val_loss['A2Grad'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['A2Grad'][lr],\n",
    "            'val_loss' : val_loss['A2Grad'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './MNIST/LR_A2Grad_' + str(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1CbtL-F0xaF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.4065497466627148, time passed 0m 19s\n",
      "Validation loss 0.42612661495290843\n",
      "Epoch 2, training loss 0.32533949986387606, time passed 1m 10s\n",
      "Validation loss 0.37711557346290964\n",
      "Epoch 4, training loss 0.31078923913632767, time passed 1m 55s\n",
      "Validation loss 0.3057402240929971\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = LR()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.99), eps=1e-8, amsgrad=True)\n",
    "    tr_loss['amsgrad'], times, val_loss['amsgrad'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "                                                         \n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['amsgrad'],\n",
    "            'val_loss' : val_loss['amsgrad'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "    torch.save(states, './MNIST/LR_amsgrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.40764180013083695, time passed 0m 20s\n",
      "Validation loss 0.40028829447166864\n",
      "Epoch 2, training loss 0.30266382122565666, time passed 1m 7s\n",
      "Validation loss 0.36440590935486555\n",
      "Epoch 4, training loss 0.28831493548777254, time passed 1m 53s\n",
      "Validation loss 0.31914368522866027\n"
     ]
    }
   ],
   "source": [
    "model = LR()\n",
    "optimizer = AccSGD(model.parameters(), lr=0.001, kappa = 1000.0, xi = 10.0)\n",
    "tr_loss['accSGD'], times, val_loss['accSGD'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "                                          \n",
    "states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['accSGD'],\n",
    "            'val_loss' : val_loss['accSGD'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "torch.save(states, './MNIST/LR_accSGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.46343427602327797, time passed 0m 34s\n",
      "Validation loss 0.6206142763416612\n",
      "Epoch 2, training loss 0.3912737628173737, time passed 1m 51s\n",
      "Validation loss 0.3956923408834107\n",
      "Epoch 4, training loss 0.3867288236060278, time passed 3m 7s\n",
      "Validation loss 0.5360902712203098\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = LR()\n",
    "    optimizer = SUG(model.parameters(), l_0=lr, momentum=0, nesterov=False)\n",
    "    tr_loss['sug'], times, val_loss['sug'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['sug'],\n",
    "            'val_loss' : val_loss['sug'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "    torch.save(states, './MNIST/LR_sug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJ24b8FFpIQU"
   },
   "source": [
    "### FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zBxqCh7YEOok"
   },
   "outputs": [],
   "source": [
    "n_epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "KlkSl5x-vPRW",
    "outputId": "0c739f08-c0ac-4326-b69d-870d51daa4a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam  lr=0.001:\n",
      "Epoch 0, training loss 0.31472805445884217, time passed 2m 17s\n",
      "Validation loss 0.33562005795256833\n",
      "Epoch 2, training loss 0.1640293464746599, time passed 7m 56s\n",
      "Validation loss 0.16987620446443386\n",
      "Epoch 4, training loss 0.1375037254112192, time passed 13m 44s\n",
      "Validation loss 0.1692539849275083\n",
      "Epoch 6, training loss 0.12588283565029146, time passed 20m 30s\n",
      "Validation loss 0.17024462949287886\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = FC()\n",
    "    print(\"Adam  lr={}:\".format(lr))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    tr_loss['Adam'][lr], times, val_loss['Adam'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['Adam'][lr],\n",
    "            'val_loss' : val_loss['Adam'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './MNIST/FC_Adam_' + str(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ODga9MkTvnRl",
    "outputId": "e1949814-6533-4078-9b5e-cf193b98398f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.2954024291499492, time passed 2m 8s\n",
      "Validation loss 0.19679289057075633\n",
      "Epoch 2, training loss 0.11406174258036991, time passed 7m 39s\n",
      "Validation loss 0.14818219451598985\n",
      "Epoch 4, training loss 0.07966713166552923, time passed 13m 13s\n",
      "Validation loss 0.10309265803739515\n",
      "Epoch 6, training loss 0.06052994809905093, time passed 18m 52s\n",
      "Validation loss 0.10621145213906528\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = FC()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.99), eps=1e-8, amsgrad=True)\n",
    "    tr_loss['amsgrad'], times, val_loss['amsgrad'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "                                                         \n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['amsgrad'],\n",
    "            'val_loss' : val_loss['amsgrad'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "    torch.save(states, './MNIST/FC_amsgrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8y30s5VE4px"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.4004168582505848, time passed 0m 36s\n",
      "Validation loss 0.26797187960428787\n",
      "Epoch 2, training loss 0.15343301741924836, time passed 1m 55s\n",
      "Validation loss 0.17337015810517428\n",
      "Epoch 4, training loss 0.10210626035243803, time passed 3m 13s\n",
      "Validation loss 0.1559533597549474\n",
      "Epoch 6, training loss 0.07533009543270398, time passed 4m 37s\n",
      "Validation loss 0.10859271298254157\n"
     ]
    }
   ],
   "source": [
    "model = FC()\n",
    "optimizer = AccSGD(model.parameters(), lr=0.001, kappa = 1000.0, xi = 10.0)\n",
    "tr_loss['accSGD'], times, val_loss['accSGD'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "                                          \n",
    "states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['accSGD'],\n",
    "            'val_loss' : val_loss['accSGD'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "torch.save(states, './MNIST/FC_accSGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.31559966881047585, time passed 1m 10s\n",
      "Validation loss 0.21523238326931807\n",
      "Epoch 2, training loss 0.12110273715224637, time passed 3m 56s\n",
      "Validation loss 0.12730560067125085\n",
      "Epoch 4, training loss 0.08468967698603876, time passed 7m 5s\n",
      "Validation loss 0.0998345566304751\n",
      "Epoch 6, training loss 0.0672137110604895, time passed 9m 58s\n",
      "Validation loss 0.08988766150243445\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = FC()\n",
    "    optimizer = SUG(model.parameters(), l_0=lr, momentum=0, nesterov=False)\n",
    "    tr_loss['sug'], times, val_loss['sug'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['sug'],\n",
    "            'val_loss' : val_loss['sug'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "    torch.save(states, './MNIST/FC_sug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MNIST.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
