{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fiSHwkvZumRd"
   },
   "outputs": [],
   "source": [
    "\n",
    "from util import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p2Mo1UdyumT9",
    "outputId": "f14053f0-1237-42a4-f9ee-f5c16460b496"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./MNIST\"\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6Lk5gvGu1Yc"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rk3Q_Jku2by"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "valid_dataset = torchvision.datasets.MNIST(root='../data', train=True, \n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYLS8LcHWv7n"
   },
   "outputs": [],
   "source": [
    "valid_size=0.15\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "               batch_size=batch_size, sampler=train_sampler,\n",
    "               num_workers=2)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(valid_dataset, \n",
    "               batch_size=batch_size, sampler=valid_sampler,\n",
    "               num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "7j9cjtv5u57l",
    "outputId": "2d6a7e4b-aa09-49fd-9dbd-d0e3f65ff814"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  tensor([6, 9, 9, 3])\n",
      "Batch shape:  torch.Size([4, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_batch(batch):\n",
    "    im = torchvision.utils.make_grid(batch)\n",
    "    plt.imshow(np.transpose(im.numpy(), (1, 2, 0)))\n",
    "    \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print('Labels: ', labels)\n",
    "print('Batch shape: ', images.size())\n",
    "show_batch(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THk9uDZku-gM"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pnS_0OICbHF4"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6micuYGbGOL"
   },
   "outputs": [],
   "source": [
    "class LR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LR, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = F.log_softmax(self.linear1(x.view(batch_size, -1)), -1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4rjRazJa-S6"
   },
   "source": [
    "###   Two-layer neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uh3HnmUmu96Q"
   },
   "outputs": [],
   "source": [
    "class FC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FC, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 256)\n",
    "        self.linear2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_relu = F.relu(self.linear1(x.view(batch_size, -1)))\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SSTdIH_vKV5"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nMttjLlZrbcd"
   },
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def model_step(model, optimizer, criterion, inputs, labels):\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    if model.training:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "    if optimizer.__class__.__name__ != 'SUG':\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            upd_outputs = model(inputs)\n",
    "            upd_loss = criterion(upd_outputs, labels)\n",
    "            upd_loss.backward()\n",
    "            return upd_loss\n",
    "\n",
    "        optimizer.step(loss, closure)\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMgATVQnvIiy"
   },
   "outputs": [],
   "source": [
    "def train(model, trainloader, criterion, optimizer, n_epochs=2, validloader=None, eps=1e-5, print_every=1):\n",
    "    tr_loss, val_loss, lips, times, grad, acc = ([] for i in range(6))\n",
    "    start_time = time.time()\n",
    "    model.to(device=device)\n",
    "    for ep in range(n_epochs):\n",
    "        model.train()\n",
    "        i = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).to(device=device), Variable(labels).to(device=device)\n",
    "\n",
    "            tr_loss.append(model_step(model, optimizer, criterion, inputs, labels))\n",
    "            if optimizer.__class__.__name__ == 'SUG':\n",
    "                lips.append(optimizer.get_lipsitz_const())\n",
    "                grad.append(optimizer.get_sq_grad)\n",
    "        times.append(time_since(start_time))\n",
    "        if ep % print_every == 0:\n",
    "            print(\"Epoch {}, training loss {}, time passed {}\".format(ep, sum(tr_loss[-i:]) / i, time_since(start_time)))\n",
    "\n",
    "        if validloader is None:\n",
    "            continue\n",
    "        model.zero_grad()\n",
    "        model.eval()\n",
    "        j = 0\n",
    "        for j, data in enumerate(validloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device=device), labels.to(device=device)\n",
    "            val_loss.append(model_step(model, optimizer, criterion, inputs, labels))\n",
    "        if ep % print_every == 0:\n",
    "            print(\"Validation loss {}\".format(sum(val_loss[-j:]) / j))\n",
    "        \n",
    "    return tr_loss, times, val_loss, lips, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sz4svVB3vNyZ"
   },
   "outputs": [],
   "source": [
    "print_every = 4\n",
    "n_epochs = 10\n",
    "tr_loss = {}\n",
    "tr_loss['sgd'] = {}\n",
    "val_loss = {}\n",
    "val_loss['sgd'] = {}\n",
    "lrs = [0.05, 0.01, 0.005]\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6jCFM66X7ql"
   },
   "outputs": [],
   "source": [
    "def concat_states(state1, state2):\n",
    "    states = {\n",
    "            'epoch': state1['epoch'] + state2['epoch'],\n",
    "            'state_dict': state2['state_dict'],\n",
    "            'optimizer': state2['optimizer'],\n",
    "            'tr_loss' : state1['tr_loss'] + state2['tr_loss'],\n",
    "            'val_loss' : state1['val_loss'] + state2['val_loss'],\n",
    "            'lips' : state1['lips'] + state2['lips'],\n",
    "            'grad' : state1['grad'] + state2['grad'],\n",
    "            #'times' : state1['times'] + list(map(lambda x: x + state1['times'][-1],state2['times']))\n",
    "             'times' : state1['times'] + state2['times']\n",
    "             }\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "98EHtawSzoTM"
   },
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "hTMWs2dYznyO",
    "outputId": "01e33386-4143-4fe1-ead2-ef3ccd13cea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD  lr=0.05, momentum=0. :\n",
      "Epoch 0, training loss 1.1780855681594937, time passed 0m 14s\n",
      "Validation loss 0.8898215400663054\n",
      "Epoch 4, training loss 0.9854220882919312, time passed 1m 28s\n",
      "Validation loss 0.7956740856658655\n",
      "Epoch 8, training loss 0.9356644755600687, time passed 2m 35s\n",
      "Validation loss 1.1033360945425692\n",
      "SGD  lr=0.01, momentum=0. :\n",
      "Epoch 0, training loss 0.41744157781241836, time passed 0m 15s\n",
      "Validation loss 0.34177317562452464\n",
      "Epoch 4, training loss 0.32298255702170864, time passed 1m 31s\n",
      "Validation loss 0.32006483330306096\n",
      "Epoch 8, training loss 0.30996284269243574, time passed 2m 45s\n",
      "Validation loss 0.34814489637442086\n",
      "SGD  lr=0.005, momentum=0. :\n",
      "Epoch 0, training loss 0.4128899209297754, time passed 0m 15s\n",
      "Validation loss 0.3270309631392942\n",
      "Epoch 4, training loss 0.2971736393977773, time passed 1m 29s\n",
      "Validation loss 0.30530539177935545\n",
      "Epoch 8, training loss 0.2849366374806503, time passed 2m 43s\n",
      "Validation loss 0.2893698387459011\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = LR()\n",
    "    print(\"SGD  lr={}, momentum=0. :\".format(lr))\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.)\n",
    "    tr_loss['sgd'][lr], times, val_loss['sgd'][lr], lips, grad = train(model, trainloader, criterion, optimizer, n_epochs=n_epochs, print_every=print_every, validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['sgd'][lr],\n",
    "            'val_loss' : val_loss['sgd'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './MNIST/LR_' + str(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1CbtL-F0xaF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.46133514287144944, time passed 0m 27s\n",
      "Validation loss 0.49703192665142754\n"
     ]
    }
   ],
   "source": [
    "l_0 = 2\n",
    "model = LR()\n",
    "optimizer = SUG(model.parameters(), l_0=l_0, momentum=0.)\n",
    "tr_loss['sug'], times, val_loss['sug'], lips, grad = train(model, trainloader, criterion, optimizer, n_epochs=n_epochs, print_every=print_every, validloader=validloader)\n",
    "states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['sug'],\n",
    "            'val_loss' : val_loss['sug'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "torch.save(states, './MNIST/LR_sug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJ24b8FFpIQU"
   },
   "source": [
    "### FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zBxqCh7YEOok"
   },
   "outputs": [],
   "source": [
    "n_epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "KlkSl5x-vPRW",
    "outputId": "0c739f08-c0ac-4326-b69d-870d51daa4a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD  lr=0.05, momentum=0. :\n",
      "Epoch 0, training loss 0.2366863005871361, time passed 0m 29s\n",
      "Validation loss 0.11924165910008008\n",
      "Epoch 4, training loss 0.036543241790046185, time passed 2m 44s\n",
      "Validation loss 0.02659412257774187\n",
      "Epoch 8, training loss 0.009252302931265622, time passed 4m 57s\n",
      "Validation loss 0.007337128495894416\n",
      "SGD  lr=0.01, momentum=0. :\n",
      "Epoch 0, training loss 0.390318907132868, time passed 0m 28s\n",
      "Validation loss 0.21850812987732113\n",
      "Epoch 4, training loss 0.07997714770486358, time passed 2m 43s\n",
      "Validation loss 0.06550830985610355\n",
      "Epoch 8, training loss 0.04263166229681311, time passed 4m 59s\n",
      "Validation loss 0.0345691220396728\n",
      "SGD  lr=0.005, momentum=0. :\n",
      "Epoch 0, training loss 0.49476544181125587, time passed 0m 28s\n",
      "Validation loss 0.2863557395032906\n",
      "Epoch 4, training loss 0.13017870467198542, time passed 2m 44s\n",
      "Validation loss 0.11114349794313609\n",
      "Epoch 8, training loss 0.0772063676231337, time passed 4m 57s\n",
      "Validation loss 0.06647039221731384\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = FC()\n",
    "    print(\"SGD  lr={}, momentum=0. :\".format(lr))\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.)\n",
    "    tr_loss['sgd'][lr], times, val_loss['sgd'][lr], lips, grad = train(model, trainloader, criterion, optimizer, n_epochs=n_epochs, print_every=print_every, validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['sgd'][lr],\n",
    "            'val_loss' : val_loss['sgd'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './MNIST/FC_' + str(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ODga9MkTvnRl",
    "outputId": "e1949814-6533-4078-9b5e-cf193b98398f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.2193387469148363, time passed 0m 59s\n",
      "Validation loss 0.11775196808452021\n",
      "Epoch 4, training loss 0.03766450093525402, time passed 5m 24s\n",
      "Validation loss 0.030662210186940927\n",
      "Epoch 8, training loss 0.017794447657136097, time passed 9m 37s\n",
      "Validation loss 0.013901273798232293\n"
     ]
    }
   ],
   "source": [
    "l_0 = 2\n",
    "model = FC()\n",
    "optimizer = SUG(model.parameters(), l_0=l_0, momentum=0.)\n",
    "tr_loss['sug'], times, val_loss['sug'], lips, grad = train(model, trainloader, criterion, optimizer, n_epochs=n_epochs, print_every=print_every, validloader=validloader)\n",
    "states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['sug'],\n",
    "            'val_loss' : val_loss['sug'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "torch.save(states, './MNIST/FC_sug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8y30s5VE4px"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MNIST.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
