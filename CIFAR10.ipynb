{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjtZDmg7YmpZ"
   },
   "source": [
    "# Experiments on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "#import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7txImi-VYhOM",
    "outputId": "0c214b61-5ca4-4873-9a55-22584be4c10e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "file_path = \"./CIFAR10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот здесь большая часть кода, откуда взята реализация (официальный репо pytorch)\n",
    "https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/cifar10_tutorial.py\n",
    "\n",
    "Реализация VGG https://github.com/kuangliu/pytorch-cifar/blob/master/models/vgg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mBA2Gv8ZqT1T"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-LK93IAGkTlD",
    "outputId": "42c3152d-ee65-4c1a-9480-7ab6d6c144af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "valid_dataset = torchvision.datasets.CIFAR10(root='../data', train=True, \n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEl5iQJ9ZZ4n"
   },
   "outputs": [],
   "source": [
    "valid_size=0.15\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "               batch_size=batch_size, sampler=train_sampler,\n",
    "               num_workers=2)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(valid_dataset, \n",
    "               batch_size=batch_size, sampler=valid_sampler,\n",
    "               num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4yhxBsWJGdsQ"
   },
   "outputs": [],
   "source": [
    "batchs_per_epoch = len(trainloader) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "LCF6wqjvqQf2",
    "outputId": "8cf7026d-48b9-4d1d-e9fc-61103fc9b234"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck\t frog\t  cat\t bird\n"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(validloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print('\\t'.join('%5s' % classes[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-VAUL8ZkoKPw"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-Su2BI5Zw_c"
   },
   "source": [
    "### Cifarnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNiBcg-QkYzu"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', \n",
    "              512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, \n",
    "              'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "#def test():\n",
    "#    net = VGG('VGG16')\n",
    "#    x = torch.randn(2,3,32,32)\n",
    "#    y = net(x)\n",
    "#    print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFUdCfE9oOwh"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P31TyRm2tcgN"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def model_step(model, optimizer, criterion, inputs, labels):\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    if model.training:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "    if optimizer.__class__.__name__ != 'SUG':\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            upd_outputs = model(inputs)\n",
    "            upd_loss = criterion(upd_outputs, labels)\n",
    "            upd_loss.backward()\n",
    "            return upd_loss\n",
    "\n",
    "        optimizer.step(loss, closure)\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECO6k5-xkzl1"
   },
   "outputs": [],
   "source": [
    "def train(model, trainloader, criterion, optimizer, n_epochs=2, validloader=None, eps=1e-5, print_every=1):\n",
    "    tr_loss, val_loss, lips, times, grad, acc = ([] for i in range(6))\n",
    "    start_time = time.time()\n",
    "    model.to(device=device)\n",
    "    for ep in range(n_epochs):\n",
    "        model.train()\n",
    "        i = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).to(device=device), Variable(labels).to(device=device)\n",
    "\n",
    "            tr_loss.append(model_step(model, optimizer, criterion, inputs, labels))\n",
    "            if optimizer.__class__.__name__ == 'SUG':\n",
    "                lips.append(optimizer.get_lipsitz_const())\n",
    "                grad.append(optimizer.get_sq_grad)\n",
    "        times.append(time_since(start_time))\n",
    "        if ep % print_every == 0:\n",
    "            print(\"Epoch {}, training loss {}, time passed {}\".format(ep, sum(tr_loss[-i:]) / i, time_since(start_time)))\n",
    "\n",
    "        if validloader is None:\n",
    "            continue\n",
    "        model.zero_grad()\n",
    "        model.eval()\n",
    "        j = 0\n",
    "        for j, data in enumerate(validloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device=device), labels.to(device=device)\n",
    "            val_loss.append(model_step(model, optimizer, criterion, inputs, labels))\n",
    "        if ep % print_every == 0:\n",
    "            print(\"Validation loss {}\".format(sum(val_loss[-j:]) / j))\n",
    "        \n",
    "    return tr_loss, times, val_loss, lips, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wX-aY0Qmi3NP"
   },
   "outputs": [],
   "source": [
    "def concat_states(state1, state2):\n",
    "    states = {\n",
    "            'epoch': state1['epoch'] + state2['epoch'],\n",
    "            'state_dict': state2['state_dict'],\n",
    "            'optimizer': state2['optimizer'],\n",
    "            'tr_loss' : state1['tr_loss'] + state2['tr_loss'],\n",
    "            'val_loss' : state1['val_loss'] + state2['val_loss'],\n",
    "            'lips' : state1['lips'] + state2['lips'],\n",
    "            'grad' : state1['grad'] + state2['grad'],\n",
    "            'times' : state1['times'] + list(map(lambda x: x + state1['times'][-1],state2['times']))\n",
    "             }\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZrx1G-ykasC"
   },
   "outputs": [],
   "source": [
    "print_every = 2\n",
    "n_epochs = 8\n",
    "tr_loss = {}\n",
    "tr_loss['accSGD'] = {}\n",
    "tr_loss['Adam'] = {}\n",
    "tr_loss['amsgrad'] = {}\n",
    "tr_loss['sug'] = {}\n",
    "tr_loss['A2GradInc'] = {}\n",
    "tr_loss['A2GradUni'] = {}\n",
    "tr_loss['A2GradExp'] = {}\n",
    "val_loss = {}\n",
    "val_loss['accSGD'] = {}\n",
    "val_loss['Adam'] = {}\n",
    "val_loss['amsgrad'] = {}\n",
    "val_loss['sug'] = {}\n",
    "val_loss['A2GradInc'] = {}\n",
    "val_loss['A2GradUni'] = {}\n",
    "val_loss['A2GradExp'] = {}\n",
    "lrs = [0.001]\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam  lr=0.001:\n",
      "Epoch 0, training loss 1.5619059246936702, time passed 0m 55s\n",
      "Validation loss 1.395797265600115\n",
      "Epoch 2, training loss 1.1838692916088727, time passed 3m 6s\n",
      "Validation loss 1.2989325432251968\n",
      "Epoch 4, training loss 1.0678610850366796, time passed 5m 16s\n",
      "Validation loss 1.2283723291124962\n",
      "Epoch 6, training loss 0.9927264514771228, time passed 7m 27s\n",
      "Validation loss 1.1363938888982177\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = CNN()\n",
    "    print(\"Adam  lr={}:\".format(lr))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    tr_loss['Adam'][lr], times, val_loss['Adam'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['Adam'][lr],\n",
    "            'val_loss' : val_loss['Adam'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/CNN_Adam_' + str(lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMSgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 1.5522522529031721, time passed 0m 57s\n",
      "Validation loss 1.3503651137731119\n",
      "Epoch 2, training loss 1.120953838430704, time passed 3m 9s\n",
      "Validation loss 1.127311502125118\n",
      "Epoch 4, training loss 0.9526293033156095, time passed 5m 19s\n",
      "Validation loss 1.1745965771671294\n",
      "Epoch 6, training loss 0.8406512876944504, time passed 7m 36s\n",
      "Validation loss 1.04886676289992\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = CNN()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.99), eps=1e-8, amsgrad=True)\n",
    "    tr_loss['amsgrad'], times, val_loss['amsgrad'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "                                                         \n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['amsgrad'],\n",
    "            'val_loss' : val_loss['amsgrad'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "    torch.save(states, './CIFAR10/CNN_amsgrad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accelerated SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 1.8840586420664767, time passed 0m 46s\n",
      "Validation loss 1.8811800922629927\n",
      "Epoch 2, training loss 1.2625865861549075, time passed 2m 33s\n",
      "Validation loss 1.6384652144372018\n",
      "Epoch 4, training loss 1.0880282887212753, time passed 4m 1s\n",
      "Validation loss 1.2731956700568774\n",
      "Epoch 6, training loss 0.9781017270982715, time passed 5m 28s\n",
      "Validation loss 1.1477524315184946\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "optimizer = AccSGD(model.parameters(), lr=0.001, kappa = 1000.0, xi = 10.0)\n",
    "tr_loss['accSGD'], times, val_loss['accSGD'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "                                          \n",
    "states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['accSGD'],\n",
    "            'val_loss' : val_loss['accSGD'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "torch.save(states, './CIFAR10/CNN_accSGD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptive SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 1.7239443657818778, time passed 1m 55s\n",
      "Validation loss 1.5204040556987042\n",
      "Epoch 2, training loss 1.2981566911933562, time passed 5m 47s\n",
      "Validation loss 1.3192244730293432\n",
      "Epoch 4, training loss 1.0969241567135575, time passed 9m 47s\n",
      "Validation loss 1.2311372176337523\n",
      "Epoch 6, training loss 0.9480354672056589, time passed 13m 20s\n",
      "Validation loss 1.2100565614001855\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = CNN()\n",
    "    optimizer = SUG(model.parameters(), l_0=lr, momentum=0, nesterov=False)\n",
    "    tr_loss['sug'], times, val_loss['sug'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['sug'],\n",
    "            'val_loss' : val_loss['sug'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "    torch.save(states, './CIFAR10/CNN_sug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2GradInc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2GradInc\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'A2Grad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-db116a39a414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A2GradInc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA2Grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     tr_loss['A2GradInc'][lr], times, val_loss['A2GradInc'][lr], lips, grad = train(model, trainloader, criterion, \n\u001b[1;32m      6\u001b[0m                                                                          \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A2Grad' is not defined"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = CNN()\n",
    "    print('A2GradInc')\n",
    "    optimizer = A2GradInc(model.parameters())\n",
    "    tr_loss['A2GradInc'][lr], times, val_loss['A2GradInc'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['A2GradInc'][lr],\n",
    "            'val_loss' : val_loss['A2GradInc'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/CNN_A2GradInc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2GradExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model = CNN()\n",
    "    print(\"A2GradExp  lr={}:\".format(lr))\n",
    "    optimizer = A2GradExp(model.parameters())\n",
    "    tr_loss['A2GradExp'][lr], times, val_loss['A2GradExp'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['A2GradExp'][lr],\n",
    "            'val_loss' : val_loss['A2GradExp'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/CNN_A2GradExp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2GradUni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model = CNN()\n",
    "    print(\"A2GradUni  lr={}:\".format(lr))\n",
    "    optimizer = A2GradUni(model.parameters())\n",
    "    tr_loss['A2GradUni'][lr], times, val_loss['A2GradUni'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['A2GradUni'][lr],\n",
    "            'val_loss' : val_loss['A2GradUni'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/CNN_A2GradUni')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam  lr=0.001:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/Pablo/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/Pablo/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/Pablo/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/Pablo/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Pablo/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/Pablo/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/Pablo/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/Pablo/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-00555443d87b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                          \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                          \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                                                          validloader=validloader)\n\u001b[0m\u001b[1;32m      9\u001b[0m     states = {\n\u001b[1;32m     10\u001b[0m             \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-855b0e20dc27>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, criterion, optimizer, n_epochs, validloader, eps, print_every)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtr_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SUG'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mlips\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lipsitz_const\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-eb0618d996ed>\u001b[0m in \u001b[0;36mmodel_step\u001b[0;34m(model, optimizer, criterion, inputs, labels)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'SUG'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = VGG('VGG16')\n",
    "    print(\"Adam  lr={}:\".format(lr))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    tr_loss['Adam'][lr], times, val_loss['Adam'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['Adam'][lr],\n",
    "            'val_loss' : val_loss['Adam'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/VGG_Adam_' + str(lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMSgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model = VGG('VGG16')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.99), eps=1e-8, amsgrad=True)\n",
    "    tr_loss['amsgrad'], times, val_loss['amsgrad'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "                                                         \n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['amsgrad'],\n",
    "            'val_loss' : val_loss['amsgrad'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "    torch.save(states, './CIFAR10/VGG_amsgrad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2GradInc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model = VGG('VGG16')\n",
    "    print('A2GradInc')\n",
    "    optimizer = A2GradInc(model.parameters())\n",
    "    tr_loss['A2GradInc'][lr], times, val_loss['A2GradInc'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['A2GradInc'][lr],\n",
    "            'val_loss' : val_loss['A2GradInc'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/VGG_A2GradInc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2GradExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model = VGG('VGG16')\n",
    "    print(\"A2GradExp  lr={}:\".format(lr))\n",
    "    optimizer = A2GradExp(model.parameters())\n",
    "    tr_loss['A2GradExp'][lr], times, val_loss['A2GradExp'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['A2GradExp'][lr],\n",
    "            'val_loss' : val_loss['A2GradExp'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/VGG_A2GradExp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2GradUni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model = VGG('VGG16')\n",
    "    print(\"A2GradUni  lr={}:\".format(lr))\n",
    "    optimizer = A2GradUni(model.parameters())\n",
    "    tr_loss['A2GradUni'][lr], times, val_loss['A2GradUni'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['A2GradUni'][lr],\n",
    "            'val_loss' : val_loss['A2GradUni'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/VGG_A2GradUni')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CIFAR10.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
