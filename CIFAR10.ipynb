{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjtZDmg7YmpZ"
   },
   "source": [
    "# Experiments on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "#import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7txImi-VYhOM",
    "outputId": "0c214b61-5ca4-4873-9a55-22584be4c10e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "file_path = \"./CIFAR10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот здесь большая часть кода, откуда взята реализация (официальный репо pytorch)\n",
    "https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/cifar10_tutorial.py\n",
    "\n",
    "Реализация VGG https://github.com/kuangliu/pytorch-cifar/blob/master/models/vgg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mBA2Gv8ZqT1T"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-LK93IAGkTlD",
    "outputId": "42c3152d-ee65-4c1a-9480-7ab6d6c144af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "valid_dataset = torchvision.datasets.CIFAR10(root='../data', train=True, \n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEl5iQJ9ZZ4n"
   },
   "outputs": [],
   "source": [
    "valid_size=0.15\n",
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "               batch_size=batch_size, sampler=train_sampler,\n",
    "               num_workers=2)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(valid_dataset, \n",
    "               batch_size=batch_size, sampler=valid_sampler,\n",
    "               num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4yhxBsWJGdsQ"
   },
   "outputs": [],
   "source": [
    "batchs_per_epoch = len(trainloader) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "LCF6wqjvqQf2",
    "outputId": "8cf7026d-48b9-4d1d-e9fc-61103fc9b234"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bird\ttruck\t ship\t ship\n"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(validloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print('\\t'.join('%5s' % classes[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-VAUL8ZkoKPw"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-Su2BI5Zw_c"
   },
   "source": [
    "### Cifarnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNiBcg-QkYzu"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', \n",
    "              512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, \n",
    "              'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "#def test():\n",
    "#    net = VGG('VGG16')\n",
    "#    x = torch.randn(2,3,32,32)\n",
    "#    y = net(x)\n",
    "#    print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFUdCfE9oOwh"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P31TyRm2tcgN"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def model_step(model, optimizer, criterion, inputs, labels):\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    if model.training:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "    if optimizer.__class__.__name__ != 'SUG':\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            upd_outputs = model(inputs)\n",
    "            upd_loss = criterion(upd_outputs, labels)\n",
    "            upd_loss.backward()\n",
    "            return upd_loss\n",
    "\n",
    "        optimizer.step(loss, closure)\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECO6k5-xkzl1"
   },
   "outputs": [],
   "source": [
    "def train(model, trainloader, criterion, optimizer, n_epochs=2, validloader=None, eps=1e-5, print_every=1):\n",
    "    tr_loss, val_loss, lips, times, grad, acc = ([] for i in range(6))\n",
    "    start_time = time.time()\n",
    "    model.to(device=device)\n",
    "    for ep in range(n_epochs):\n",
    "        model.train()\n",
    "        i = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).to(device=device), Variable(labels).to(device=device)\n",
    "\n",
    "            tr_loss.append(model_step(model, optimizer, criterion, inputs, labels))\n",
    "            if optimizer.__class__.__name__ == 'SUG':\n",
    "                lips.append(optimizer.get_lipsitz_const())\n",
    "                grad.append(optimizer.get_sq_grad)\n",
    "        times.append(time_since(start_time))\n",
    "        if ep % print_every == 0:\n",
    "            print(\"Epoch {}, training loss {}, time passed {}\".format(ep, sum(tr_loss[-i:]) / i, time_since(start_time)))\n",
    "\n",
    "        if validloader is None:\n",
    "            continue\n",
    "        model.zero_grad()\n",
    "        model.eval()\n",
    "        j = 0\n",
    "        for j, data in enumerate(validloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device=device), labels.to(device=device)\n",
    "            val_loss.append(model_step(model, optimizer, criterion, inputs, labels))\n",
    "        if ep % print_every == 0:\n",
    "            print(\"Validation loss {}\".format(sum(val_loss[-j:]) / j))\n",
    "        \n",
    "    return tr_loss, times, val_loss, lips, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wX-aY0Qmi3NP"
   },
   "outputs": [],
   "source": [
    "def concat_states(state1, state2):\n",
    "    states = {\n",
    "            'epoch': state1['epoch'] + state2['epoch'],\n",
    "            'state_dict': state2['state_dict'],\n",
    "            'optimizer': state2['optimizer'],\n",
    "            'tr_loss' : state1['tr_loss'] + state2['tr_loss'],\n",
    "            'val_loss' : state1['val_loss'] + state2['val_loss'],\n",
    "            'lips' : state1['lips'] + state2['lips'],\n",
    "            'grad' : state1['grad'] + state2['grad'],\n",
    "            'times' : state1['times'] + list(map(lambda x: x + state1['times'][-1],state2['times']))\n",
    "             }\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZrx1G-ykasC"
   },
   "outputs": [],
   "source": [
    "print_every = 2\n",
    "n_epochs = 8\n",
    "tr_loss = {}\n",
    "tr_loss['accSGD'] = {}\n",
    "tr_loss['Adam'] = {}\n",
    "tr_loss['amsgrad'] = {}\n",
    "tr_loss['sug'] = {}\n",
    "tr_loss['A2GradInc'] = {}\n",
    "tr_loss['A2GradUni'] = {}\n",
    "tr_loss['A2GradExp'] = {}\n",
    "val_loss = {}\n",
    "val_loss['accSGD'] = {}\n",
    "val_loss['Adam'] = {}\n",
    "val_loss['amsgrad'] = {}\n",
    "val_loss['sug'] = {}\n",
    "val_loss['A2GradInc'] = {}\n",
    "val_loss['A2GradUni'] = {}\n",
    "val_loss['A2GradExp'] = {}\n",
    "lrs = [0.001]\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam  lr=0.001:\n",
      "Epoch 0, training loss 1.5619059246936702, time passed 0m 55s\n",
      "Validation loss 1.395797265600115\n",
      "Epoch 2, training loss 1.1838692916088727, time passed 3m 6s\n",
      "Validation loss 1.2989325432251968\n",
      "Epoch 4, training loss 1.0678610850366796, time passed 5m 16s\n",
      "Validation loss 1.2283723291124962\n",
      "Epoch 6, training loss 0.9927264514771228, time passed 7m 27s\n",
      "Validation loss 1.1363938888982177\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = CNN()\n",
    "    print(\"Adam  lr={}:\".format(lr))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    tr_loss['Adam'][lr], times, val_loss['Adam'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['Adam'][lr],\n",
    "            'val_loss' : val_loss['Adam'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/CNN_Adam_' + str(lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMSgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 1.5522522529031721, time passed 0m 57s\n",
      "Validation loss 1.3503651137731119\n",
      "Epoch 2, training loss 1.120953838430704, time passed 3m 9s\n",
      "Validation loss 1.127311502125118\n",
      "Epoch 4, training loss 0.9526293033156095, time passed 5m 19s\n",
      "Validation loss 1.1745965771671294\n",
      "Epoch 6, training loss 0.8406512876944504, time passed 7m 36s\n",
      "Validation loss 1.04886676289992\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = CNN()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.99), eps=1e-8, amsgrad=True)\n",
    "    tr_loss['amsgrad'], times, val_loss['amsgrad'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "                                                         \n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['amsgrad'],\n",
    "            'val_loss' : val_loss['amsgrad'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "    torch.save(states, './CIFAR10/CNN_amsgrad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accelerated SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 1.8840586420664767, time passed 0m 46s\n",
      "Validation loss 1.8811800922629927\n",
      "Epoch 2, training loss 1.2625865861549075, time passed 2m 33s\n",
      "Validation loss 1.6384652144372018\n",
      "Epoch 4, training loss 1.0880282887212753, time passed 4m 1s\n",
      "Validation loss 1.2731956700568774\n",
      "Epoch 6, training loss 0.9781017270982715, time passed 5m 28s\n",
      "Validation loss 1.1477524315184946\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "optimizer = AccSGD(model.parameters(), lr=0.001, kappa = 1000.0, xi = 10.0)\n",
    "tr_loss['accSGD'], times, val_loss['accSGD'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "                                          \n",
    "states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['accSGD'],\n",
    "            'val_loss' : val_loss['accSGD'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "torch.save(states, './CIFAR10/CNN_accSGD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptive SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 1.7160492355469614, time passed 3m 5s\n",
      "Validation loss 1.4749174501146554\n",
      "Epoch 2, training loss 1.2525665010662232, time passed 7m 19s\n",
      "Validation loss 1.2477889744487363\n",
      "Epoch 4, training loss 1.067492834749598, time passed 11m 4s\n",
      "Validation loss 1.1675659322687757\n",
      "Epoch 6, training loss 0.9256623194171453, time passed 15m 5s\n",
      "Validation loss 1.1762307366731963\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = CNN()\n",
    "    optimizer = SUG(model.parameters(), l_0=lr, momentum=0, nesterov=False)\n",
    "    tr_loss['sug'], times, val_loss['sug'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['sug'],\n",
    "            'val_loss' : val_loss['sug'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "    torch.save(states, './CIFAR10/CNN_sug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2GradInc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2GradInc\n",
      "Epoch 0, training loss 1.8954763923580926, time passed 0m 41s\n",
      "Validation loss 1.7763475310713404\n",
      "Epoch 2, training loss 1.6979682360360602, time passed 2m 27s\n",
      "Validation loss 1.712695634861257\n",
      "Epoch 4, training loss 1.622521726933521, time passed 4m 2s\n",
      "Validation loss 1.5941723119805438\n",
      "Epoch 6, training loss 1.5578404663226018, time passed 5m 40s\n",
      "Validation loss 1.5549846551397948\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = CNN()\n",
    "    print('A2GradInc')\n",
    "    optimizer = A2GradInc(model.parameters(), beta=5, lips=10)\n",
    "    tr_loss['A2GradInc'][lr], times, val_loss['A2GradInc'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['A2GradInc'][lr],\n",
    "            'val_loss' : val_loss['A2GradInc'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/CNN_A2GradInc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2GradExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2GradExp  lr=0.001:\n",
      "Epoch 0, training loss 1.9450582547607012, time passed 0m 41s\n",
      "Validation loss 1.8914221327676335\n",
      "Epoch 2, training loss 1.8010226714492112, time passed 2m 16s\n",
      "Validation loss 1.7759289370656903\n",
      "Epoch 4, training loss 1.7448809497697975, time passed 3m 53s\n",
      "Validation loss 1.678396025233233\n",
      "Epoch 6, training loss 1.6877969361291862, time passed 21m 36s\n",
      "Validation loss 1.6874131423559362\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = CNN()\n",
    "    print(\"A2GradExp  lr={}:\".format(lr))\n",
    "    optimizer = A2GradExp(model.parameters(), beta=5, lips=10, rho=0.99)\n",
    "    tr_loss['A2GradExp'][lr], times, val_loss['A2GradExp'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['A2GradExp'][lr],\n",
    "            'val_loss' : val_loss['A2GradExp'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/CNN_A2GradExp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2GradUni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2GradUni  lr=0.001:\n",
      "Epoch 0, training loss 1.885427249954587, time passed 0m 44s\n",
      "Validation loss 1.7669530588509306\n",
      "Epoch 2, training loss 1.6846244645877235, time passed 2m 28s\n",
      "Validation loss 1.6855964011481885\n",
      "Epoch 4, training loss 1.6142121050534881, time passed 4m 2s\n",
      "Validation loss 1.5925247664130993\n",
      "Epoch 6, training loss 1.5519584719013109, time passed 5m 45s\n",
      "Validation loss 1.5557561303978924\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = CNN()\n",
    "    print(\"A2GradUni  lr={}:\".format(lr))\n",
    "    optimizer = A2GradUni(model.parameters(), beta=5, lips=10,)\n",
    "    tr_loss['A2GradUni'][lr], times, val_loss['A2GradUni'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['A2GradUni'][lr],\n",
    "            'val_loss' : val_loss['A2GradUni'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/CNN_A2GradUni')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam  lr=0.001:\n"
     ]
    }
   ],
   "source": [
    "for lr in lrs:\n",
    "    model = VGG('VGG16')\n",
    "    print(\"Adam  lr={}:\".format(lr))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    tr_loss['Adam'][lr], times, val_loss['Adam'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['Adam'][lr],\n",
    "            'val_loss' : val_loss['Adam'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/VGG_Adam_' + str(lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMSgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model = VGG('VGG16')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.99), eps=1e-8, amsgrad=True)\n",
    "    tr_loss['amsgrad'], times, val_loss['amsgrad'], lips, grad = train(model, trainloader, criterion, optimizer, \n",
    "                                                           n_epochs=n_epochs, print_every=print_every, \n",
    "                                                           validloader=validloader)\n",
    "                                                         \n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['amsgrad'],\n",
    "            'val_loss' : val_loss['amsgrad'],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "         }\n",
    "    torch.save(states, './CIFAR10/VGG_amsgrad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2GradInc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model = VGG('VGG16')\n",
    "    print('A2GradInc')\n",
    "    optimizer = A2GradInc(model.parameters())\n",
    "    tr_loss['A2GradInc'][lr], times, val_loss['A2GradInc'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['A2GradInc'][lr],\n",
    "            'val_loss' : val_loss['A2GradInc'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/VGG_A2GradInc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2GradExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model = VGG('VGG16')\n",
    "    print(\"A2GradExp  lr={}:\".format(lr))\n",
    "    optimizer = A2GradExp(model.parameters())\n",
    "    tr_loss['A2GradExp'][lr], times, val_loss['A2GradExp'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['A2GradExp'][lr],\n",
    "            'val_loss' : val_loss['A2GradExp'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/VGG_A2GradExp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A2GradUni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in lrs:\n",
    "    model = VGG('VGG16')\n",
    "    print(\"A2GradUni  lr={}:\".format(lr))\n",
    "    optimizer = A2GradUni(model.parameters())\n",
    "    tr_loss['A2GradUni'][lr], times, val_loss['A2GradUni'][lr], lips, grad = train(model, trainloader, criterion, \n",
    "                                                                         optimizer, n_epochs=n_epochs, \n",
    "                                                                         print_every=print_every, \n",
    "                                                                         validloader=validloader)\n",
    "    states = {\n",
    "            'epoch': n_epochs,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'tr_loss' : tr_loss['A2GradUni'][lr],\n",
    "            'val_loss' : val_loss['A2GradUni'][lr],\n",
    "            'lips' : lips,\n",
    "            'grad' : grad,\n",
    "            'times' : times\n",
    "             }\n",
    "    torch.save(states, './CIFAR10/VGG_A2GradUni')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CIFAR10.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
